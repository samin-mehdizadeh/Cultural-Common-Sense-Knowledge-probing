{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1WTS8RC7YUlZculUYvl0FrLka3Xsj72n9","timestamp":1673036287925}],"authorship_tag":"ABX9TyONx4VNRzla2XcfsHw3KXgJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"b19a7dc976d64461b7243584dcea1f2b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_707174c3db484f5d8f9012bae3aef419","IPY_MODEL_f96356b6f7594ac1ac7332c68c960e82","IPY_MODEL_6f9d6eb48d4a433588827577e89c962c"],"layout":"IPY_MODEL_46cff16a8632416781bf976a9086d9ac"}},"707174c3db484f5d8f9012bae3aef419":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bb87268c1cf42f6813a3fe8e5fa56e6","placeholder":"​","style":"IPY_MODEL_7664cd4a75c1464aa608ed1b1c07dc39","value":"100%"}},"f96356b6f7594ac1ac7332c68c960e82":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3201912a6697498887bf43b3d16655f1","max":2975,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a51af1f082d4d53adadc1cd264735a3","value":2975}},"6f9d6eb48d4a433588827577e89c962c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ce3464a18604c13955f411f926972c4","placeholder":"​","style":"IPY_MODEL_fd7e270797794c2295ebf5816b2b5a9a","value":" 2975/2975 [00:53&lt;00:00, 60.89it/s]"}},"46cff16a8632416781bf976a9086d9ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bb87268c1cf42f6813a3fe8e5fa56e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7664cd4a75c1464aa608ed1b1c07dc39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3201912a6697498887bf43b3d16655f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a51af1f082d4d53adadc1cd264735a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ce3464a18604c13955f411f926972c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd7e270797794c2295ebf5816b2b5a9a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df4eb1a6ab1d4063ad8684a960a8dbc0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_154498c9ad894e8fa8e640f09c3ae2b7","IPY_MODEL_70b1e8e4820649f8a549c9c3a0427599","IPY_MODEL_282575bafb194d3ab9f7bf4cfc06274e"],"layout":"IPY_MODEL_d7ae865acbf64b7e9036057e3ee5f3ad"}},"154498c9ad894e8fa8e640f09c3ae2b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7cdcc61f3c34bb6bbe6c0698e27dd58","placeholder":"​","style":"IPY_MODEL_5890cd7d95d54128af88d3b68fbc767a","value":"100%"}},"70b1e8e4820649f8a549c9c3a0427599":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_367fab8ae5b14b9cb3643ae07bfac94c","max":2975,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71fc793fca834683853cf83f69ec30c4","value":2975}},"282575bafb194d3ab9f7bf4cfc06274e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49386c77491f42ab98166ac92104e098","placeholder":"​","style":"IPY_MODEL_f8826dc88563458b8ed90911f13da1ee","value":" 2975/2975 [04:13&lt;00:00, 13.45it/s]"}},"d7ae865acbf64b7e9036057e3ee5f3ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7cdcc61f3c34bb6bbe6c0698e27dd58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5890cd7d95d54128af88d3b68fbc767a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"367fab8ae5b14b9cb3643ae07bfac94c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71fc793fca834683853cf83f69ec30c4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49386c77491f42ab98166ac92104e098":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8826dc88563458b8ed90911f13da1ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89dE87GSx50J","executionInfo":{"status":"ok","timestamp":1673036373031,"user_tz":-210,"elapsed":36762,"user":{"displayName":"Samin Mehdizadehsani","userId":"02586135374726691422"}},"outputId":"5b925c4d-74e7-47bc-d13b-bbbde706fe5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets\n","  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 KB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: tokenizers, xxhash, urllib3, multiprocess, responses, huggingface-hub, transformers, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.8.0 huggingface-hub-0.11.1 multiprocess-0.70.14 responses-0.18.0 tokenizers-0.13.2 transformers-4.25.1 urllib3-1.26.13 xxhash-3.2.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting kaleido\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: kaleido\n","Successfully installed kaleido-0.2.1\n","Downloading...\n","From: https://drive.google.com/uc?id=1esdw31qkrJYh0OCU16csy5XKVK_wLmzi\n","To: /content/en_data.csv\n","100% 763k/763k [00:00<00:00, 146MB/s]\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}],"source":["! pip install transformers datasets\n","! pip install -U kaleido\n","! gdown 1esdw31qkrJYh0OCU16csy5XKVK_wLmzi\n","! pip install sentencepiece"]},{"cell_type":"markdown","source":["## 1) ELECTRA - FAKE TOKENS"],"metadata":{"id":"JdeniLWJeu_u"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from tqdm.auto import tqdm\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import seaborn as sn\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import RocCurveDisplay\n","from sklearn.metrics import classification_report\n","from transformers import ElectraForPreTraining, ElectraTokenizerFast\n","import torch\n","from transformers import ElectraTokenizer, ElectraForMultipleChoice\n","from transformers import RobertaTokenizer, RobertaForMultipleChoice\n","from transformers import BertTokenizer, BertForMultipleChoice\n","from transformers import XLMRobertaTokenizer, XLMRobertaForMultipleChoice\n","import random\n","\n","plt.style.use(\"ggplot\")\n","pd.set_option('display.max_colwidth', None)\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","DEVICE"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"YOB6YdJvyacB","executionInfo":{"status":"ok","timestamp":1673036380305,"user_tz":-210,"elapsed":7285,"user":{"displayName":"Samin Mehdizadehsani","userId":"02586135374726691422"}},"outputId":"7ec30c00-92f7-44d0-c54b-1fd946f6e8df"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["df1 = pd.read_csv(\"en_data.csv\")"],"metadata":{"id":"r9BrUDXrybVo","executionInfo":{"status":"ok","timestamp":1673037645203,"user_tz":-210,"elapsed":522,"user":{"displayName":"Samin Mehdizadehsani","userId":"02586135374726691422"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["discriminator = ElectraForPreTraining.from_pretrained(\"google/electra-base-discriminator\")\n","tokenizer = ElectraTokenizerFast.from_pretrained(\"google/electra-base-discriminator\")\n","def run_electra(sentence: str):\n","    discriminator.eval()\n","    discriminator.to(DEVICE)\n","    tokens = tokenizer.tokenize(sentence)\n","    inputs = tokenizer.encode(sentence, return_tensors=\"pt\").to(DEVICE)\n","    discriminator_outputs = discriminator(inputs)\n","    return tokens, torch.round((torch.sign(discriminator_outputs[0]) + 1) / 2).cpu().detach().numpy()[0]\n"],"metadata":{"id":"d7oBUb9dypOo","executionInfo":{"status":"ok","timestamp":1673037650782,"user_tz":-210,"elapsed":3360,"user":{"displayName":"Samin Mehdizadehsani","userId":"02586135374726691422"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["discriminator.eval()\n","discriminator.to(DEVICE)\n","sentence = \"The table brown fox jumps over the happy\"\n","tokens = tokenizer.tokenize(sentence)\n","inputs = tokenizer.encode(sentence, return_tensors=\"pt\").to(DEVICE)\n","discriminator_outputs = discriminator(inputs)\n","print((torch.sign(discriminator_outputs[0])))\n","tokens, torch.round((torch.sign(discriminator_outputs[0]) + 1) / 2).cpu().detach().numpy()[0]"],"metadata":{"id":"N9vWisGvpCeU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fake_sentence = \"The table brown fox jumps over the fake\"\n","tokens, logits = run_electra(fake_sentence)\n","logits = logits[1:-1]\n","print(logits.mean(), list(zip(tokens, logits)))\n","\n","fake_sentence = \"The quick brown fox fake over the lazy dog\"\n","tokens, logits = run_electra(fake_sentence)\n","logits = logits[1:-1]\n","print(logits.mean(), list(zip(tokens, logits)))\n","print(logits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6o0wx098ooHX","executionInfo":{"status":"ok","timestamp":1673037655347,"user_tz":-210,"elapsed":1036,"user":{"displayName":"Samin Mehdizadehsani","userId":"02586135374726691422"}},"outputId":"eac6f457-76da-4c36-b7e5-991ddb9f283a"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["0.125 [('the', 0.0), ('table', 0.0), ('brown', 0.0), ('fox', 0.0), ('jumps', 0.0), ('over', 0.0), ('the', 0.0), ('fake', 1.0)]\n","0.11111111 [('the', 0.0), ('quick', 0.0), ('brown', 0.0), ('fox', 0.0), ('fake', 1.0), ('over', 0.0), ('the', 0.0), ('lazy', 0.0), ('dog', 0.0)]\n","[0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"]}]},{"cell_type":"code","source":["results = {\"tokens\": [], \"predicts\": []}\n","for i, row in tqdm(df1.iterrows(), total=len(df1)):\n","    tokens, predicts = run_electra(row[\"sentence\"])\n","    results[\"tokens\"].append(tokens)\n","    results[\"predicts\"].append(predicts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["b19a7dc976d64461b7243584dcea1f2b","707174c3db484f5d8f9012bae3aef419","f96356b6f7594ac1ac7332c68c960e82","6f9d6eb48d4a433588827577e89c962c","46cff16a8632416781bf976a9086d9ac","9bb87268c1cf42f6813a3fe8e5fa56e6","7664cd4a75c1464aa608ed1b1c07dc39","3201912a6697498887bf43b3d16655f1","7a51af1f082d4d53adadc1cd264735a3","0ce3464a18604c13955f411f926972c4","fd7e270797794c2295ebf5816b2b5a9a"]},"id":"17Xt-PQ6yvjq","executionInfo":{"status":"ok","timestamp":1673037712831,"user_tz":-210,"elapsed":54442,"user":{"displayName":"Samin Mehdizadehsani","userId":"02586135374726691422"}},"outputId":"f7a82fad-7827-4638-9e50-48a585e12662"},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2975 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b19a7dc976d64461b7243584dcea1f2b"}},"metadata":{}}]},{"cell_type":"code","source":["df1[\"fake\"] = df1[\"label\"].apply(lambda x: False if x == \"T\" else True)\n","df1[\"tokens\"] = results[\"tokens\"]\n","df1[\"predicts\"] = results[\"predicts\"]\n","df1[\"sum_predicts\"] = [int(np.sum(a)) for a in results[\"predicts\"]]\n","df1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ogY8NjG-1wQa","executionInfo":{"status":"ok","timestamp":1673037726197,"user_tz":-210,"elapsed":602,"user":{"displayName":"Samin Mehdizadehsani","userId":"02586135374726691422"}},"outputId":"a30f6a22-8d58-42af-a7a8-09cb76c683c7"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Unnamed: 0  \\\n","0              0   \n","1              1   \n","2              2   \n","3              3   \n","4              4   \n","...          ...   \n","2970        2970   \n","2971        2971   \n","2972        2972   \n","2973        2973   \n","2974        2974   \n","\n","                                                                                                 mask  \\\n","0                                                           Most of Kenya is located in <mask> areas.   \n","1     In Kenya 30 years ago, the <mask> was the most popular means of transportation in major cities.   \n","2                                              The unit of measurement for height in China is <mask>.   \n","3                                                         The American normally eat food with <mask>.   \n","4                             In the United States wedding ceremony normally lasts <mask> than a day.   \n","...                                                                                               ...   \n","2970        In Iran 30 years ago, the <mask> was the most popular means of transport in large cities.   \n","2971                                           The unit for measuring temperature in China is <mask>.   \n","2972                                           The most popular sport in the United States is <mask>.   \n","2973                                                Month appears <mask> year in Chinese date format.   \n","2974                                  In United States, month appears <mask> year in the date format.   \n","\n","                                                                                           sentence  \\\n","0                                                    Most of Kenya is located in continental areas.   \n","1     In Kenya 30 years ago, the boat was the most popular means of transportation in major cities.   \n","2                                        The unit of measurement for height in China is centimeter.   \n","3                                                         The American normally eat food with hand.   \n","4                             In the United States wedding ceremony normally lasts less than a day.   \n","...                                                                                             ...   \n","2970       In Iran 30 years ago, the metro was the most popular means of transport in large cities.   \n","2971                                        The unit for measuring temperature in China is Rankine.   \n","2972                                         The most popular sport in the United States is soccer.   \n","2973                                              Month appears before year in Chinese date format.   \n","2974                                In United States, month appears before year in the date format.   \n","\n","                                                                               original prompt  \\\n","0                                                        Most part of Kenya is in <mask> zone.   \n","1     In Kenya, the most popular mode of transportation in big cities 30 years ago was <mask>.   \n","2                                             The unit of measuring height is <mask> in China.   \n","3                                                American people usually eat food with <mask>.   \n","4                             In United States, weddings usually last for <mask> than one day.   \n","...                                                                                        ...   \n","2970   In Iran, the most popular mode of transportation in big cities 30 years ago was <mask>.   \n","2971                                     The unit of measuring temperature is <mask> in China.   \n","2972                                       The most popular sports in United States is <mask>.   \n","2973                                   In China, month appears <mask> year in the date format.   \n","2974                           In United States, month appears <mask> year in the date format.   \n","\n","            country           context                     correct Ans  \\\n","0             Kenya           climate                        tropical   \n","1             Kenya    transportation                        bus, car   \n","2             China  measurement unit               meter, centimeter   \n","3     United States    food and drink                     knife, fork   \n","4     United States           wedding                            less   \n","...             ...               ...                             ...   \n","2970           Iran    transportation                             car   \n","2971          China  measurement unit                         Celsius   \n","2972  United States            sports  football, basketball, baseball   \n","2973          China       date format                           after   \n","2974  United States       date format                          before   \n","\n","              Ans    GPT-3 Pred GPT-3 Pred (T/F/I)  paraphrase label   fake  \\\n","0     continental  Not Reported       Not Reported        True     F   True   \n","1            boat  Not Reported       Not Reported        True     F   True   \n","2      centimeter  Not Reported       Not Reported        True     T  False   \n","3            hand  Not Reported       Not Reported        True     F   True   \n","4            less  Not Reported       Not Reported        True     T  False   \n","...           ...           ...                ...         ...   ...    ...   \n","2970        metro  Not Reported       Not Reported        True     F   True   \n","2971      Rankine  Not Reported       Not Reported        True     F   True   \n","2972       soccer  Not Reported       Not Reported        True     F   True   \n","2973       before  Not Reported       Not Reported        True     F   True   \n","2974       before        before                  T       False     T  False   \n","\n","                                                                                                                   tokens  \\\n","0                                                               [most, of, kenya, is, located, in, continental, areas, .]   \n","1     [in, kenya, 30, years, ago, ,, the, boat, was, the, most, popular, means, of, transportation, in, major, cities, .]   \n","2                                             [the, unit, of, measurement, for, height, in, china, is, cent, ##imeter, .]   \n","3                                                                     [the, american, normally, eat, food, with, hand, .]   \n","4                                    [in, the, united, states, wedding, ceremony, normally, lasts, less, than, a, day, .]   \n","...                                                                                                                   ...   \n","2970       [in, iran, 30, years, ago, ,, the, metro, was, the, most, popular, means, of, transport, in, large, cities, .]   \n","2971                                              [the, unit, for, measuring, temperature, in, china, is, rankin, ##e, .]   \n","2972                                                  [the, most, popular, sport, in, the, united, states, is, soccer, .]   \n","2973                                                         [month, appears, before, year, in, chinese, date, format, .]   \n","2974                                      [in, united, states, ,, month, appears, before, year, in, the, date, format, .]   \n","\n","                                                                                                       predicts  \\\n","0                                                       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","2                                        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","3                                                            [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","4                                   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","...                                                                                                         ...   \n","2970  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","2971                                          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","2972                                          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","2973                                                    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","2974                                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n","\n","      sum_predicts  \n","0                0  \n","1                0  \n","2                0  \n","3                0  \n","4                0  \n","...            ...  \n","2970             0  \n","2971             0  \n","2972             0  \n","2973             0  \n","2974             0  \n","\n","[2975 rows x 16 columns]"],"text/html":["\n","  <div id=\"df-8669ae2f-344a-45da-b664-53294a4fcaab\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>mask</th>\n","      <th>sentence</th>\n","      <th>original prompt</th>\n","      <th>country</th>\n","      <th>context</th>\n","      <th>correct Ans</th>\n","      <th>Ans</th>\n","      <th>GPT-3 Pred</th>\n","      <th>GPT-3 Pred (T/F/I)</th>\n","      <th>paraphrase</th>\n","      <th>label</th>\n","      <th>fake</th>\n","      <th>tokens</th>\n","      <th>predicts</th>\n","      <th>sum_predicts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Most of Kenya is located in &lt;mask&gt; areas.</td>\n","      <td>Most of Kenya is located in continental areas.</td>\n","      <td>Most part of Kenya is in &lt;mask&gt; zone.</td>\n","      <td>Kenya</td>\n","      <td>climate</td>\n","      <td>tropical</td>\n","      <td>continental</td>\n","      <td>Not Reported</td>\n","      <td>Not Reported</td>\n","      <td>True</td>\n","      <td>F</td>\n","      <td>True</td>\n","      <td>[most, of, kenya, is, located, in, continental, areas, .]</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>In Kenya 30 years ago, the &lt;mask&gt; was the most popular means of transportation in major cities.</td>\n","      <td>In Kenya 30 years ago, the boat was the most popular means of transportation in major cities.</td>\n","      <td>In Kenya, the most popular mode of transportation in big cities 30 years ago was &lt;mask&gt;.</td>\n","      <td>Kenya</td>\n","      <td>transportation</td>\n","      <td>bus, car</td>\n","      <td>boat</td>\n","      <td>Not Reported</td>\n","      <td>Not Reported</td>\n","      <td>True</td>\n","      <td>F</td>\n","      <td>True</td>\n","      <td>[in, kenya, 30, years, ago, ,, the, boat, was, the, most, popular, means, of, transportation, in, major, cities, .]</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>The unit of measurement for height in China is &lt;mask&gt;.</td>\n","      <td>The unit of measurement for height in China is centimeter.</td>\n","      <td>The unit of measuring height is &lt;mask&gt; in China.</td>\n","      <td>China</td>\n","      <td>measurement unit</td>\n","      <td>meter, centimeter</td>\n","      <td>centimeter</td>\n","      <td>Not Reported</td>\n","      <td>Not Reported</td>\n","      <td>True</td>\n","      <td>T</td>\n","      <td>False</td>\n","      <td>[the, unit, of, measurement, for, height, in, china, is, cent, ##imeter, .]</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>The American normally eat food with &lt;mask&gt;.</td>\n","      <td>The American normally eat food with hand.</td>\n","      <td>American people usually eat food with &lt;mask&gt;.</td>\n","      <td>United States</td>\n","      <td>food and drink</td>\n","      <td>knife, fork</td>\n","      <td>hand</td>\n","      <td>Not Reported</td>\n","      <td>Not Reported</td>\n","      <td>True</td>\n","      <td>F</td>\n","      <td>True</td>\n","      <td>[the, american, normally, eat, food, with, hand, .]</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>In the United States wedding ceremony normally lasts &lt;mask&gt; than a day.</td>\n","      <td>In the United States wedding ceremony normally lasts less than a day.</td>\n","      <td>In United States, weddings usually last for &lt;mask&gt; than one day.</td>\n","      <td>United States</td>\n","      <td>wedding</td>\n","      <td>less</td>\n","      <td>less</td>\n","      <td>Not Reported</td>\n","      <td>Not Reported</td>\n","      <td>True</td>\n","      <td>T</td>\n","      <td>False</td>\n","      <td>[in, the, united, states, wedding, ceremony, normally, lasts, less, than, a, day, .]</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2970</th>\n","      <td>2970</td>\n","      <td>In Iran 30 years ago, the &lt;mask&gt; was the most popular means of transport in large cities.</td>\n","      <td>In Iran 30 years ago, the metro was the most popular means of transport in large cities.</td>\n","      <td>In Iran, the most popular mode of transportation in big cities 30 years ago was &lt;mask&gt;.</td>\n","      <td>Iran</td>\n","      <td>transportation</td>\n","      <td>car</td>\n","      <td>metro</td>\n","      <td>Not Reported</td>\n","      <td>Not Reported</td>\n","      <td>True</td>\n","      <td>F</td>\n","      <td>True</td>\n","      <td>[in, iran, 30, years, ago, ,, the, metro, was, the, most, popular, means, of, transport, in, large, cities, .]</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2971</th>\n","      <td>2971</td>\n","      <td>The unit for measuring temperature in China is &lt;mask&gt;.</td>\n","      <td>The unit for measuring temperature in China is Rankine.</td>\n","      <td>The unit of measuring temperature is &lt;mask&gt; in China.</td>\n","      <td>China</td>\n","      <td>measurement unit</td>\n","      <td>Celsius</td>\n","      <td>Rankine</td>\n","      <td>Not Reported</td>\n","      <td>Not Reported</td>\n","      <td>True</td>\n","      <td>F</td>\n","      <td>True</td>\n","      <td>[the, unit, for, measuring, temperature, in, china, is, rankin, ##e, .]</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2972</th>\n","      <td>2972</td>\n","      <td>The most popular sport in the United States is &lt;mask&gt;.</td>\n","      <td>The most popular sport in the United States is soccer.</td>\n","      <td>The most popular sports in United States is &lt;mask&gt;.</td>\n","      <td>United States</td>\n","      <td>sports</td>\n","      <td>football, basketball, baseball</td>\n","      <td>soccer</td>\n","      <td>Not Reported</td>\n","      <td>Not Reported</td>\n","      <td>True</td>\n","      <td>F</td>\n","      <td>True</td>\n","      <td>[the, most, popular, sport, in, the, united, states, is, soccer, .]</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2973</th>\n","      <td>2973</td>\n","      <td>Month appears &lt;mask&gt; year in Chinese date format.</td>\n","      <td>Month appears before year in Chinese date format.</td>\n","      <td>In China, month appears &lt;mask&gt; year in the date format.</td>\n","      <td>China</td>\n","      <td>date format</td>\n","      <td>after</td>\n","      <td>before</td>\n","      <td>Not Reported</td>\n","      <td>Not Reported</td>\n","      <td>True</td>\n","      <td>F</td>\n","      <td>True</td>\n","      <td>[month, appears, before, year, in, chinese, date, format, .]</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2974</th>\n","      <td>2974</td>\n","      <td>In United States, month appears &lt;mask&gt; year in the date format.</td>\n","      <td>In United States, month appears before year in the date format.</td>\n","      <td>In United States, month appears &lt;mask&gt; year in the date format.</td>\n","      <td>United States</td>\n","      <td>date format</td>\n","      <td>before</td>\n","      <td>before</td>\n","      <td>before</td>\n","      <td>T</td>\n","      <td>False</td>\n","      <td>T</td>\n","      <td>False</td>\n","      <td>[in, united, states, ,, month, appears, before, year, in, the, date, format, .]</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2975 rows × 16 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8669ae2f-344a-45da-b664-53294a4fcaab')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8669ae2f-344a-45da-b664-53294a4fcaab button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8669ae2f-344a-45da-b664-53294a4fcaab');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["df1[\"electra_label\"] = np.where(df1.sum_predicts == 0,\"T\",\"F\")"],"metadata":{"id":"_j5wt3Wh2A7G","executionInfo":{"status":"ok","timestamp":1673037730729,"user_tz":-210,"elapsed":544,"user":{"displayName":"Samin Mehdizadehsani","userId":"02586135374726691422"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["print(classification_report(df1['label'], df1['electra_label']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ZAU2EO1lwL5","executionInfo":{"status":"ok","timestamp":1673037732800,"user_tz":-210,"elapsed":4,"user":{"displayName":"Samin Mehdizadehsani","userId":"02586135374726691422"}},"outputId":"17b62734-0883-45ca-c4cc-591cae98bca0"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           F       0.83      0.08      0.15      2220\n","           T       0.26      0.95      0.41       755\n","\n","    accuracy                           0.30      2975\n","   macro avg       0.55      0.52      0.28      2975\n","weighted avg       0.69      0.30      0.22      2975\n","\n"]}]},{"cell_type":"markdown","source":["##2) Question-Answer"],"metadata":{"id":"hNlgCtcmDxOU"}},{"cell_type":"code","source":["df = pd.read_csv(\"en_data.csv\")"],"metadata":{"id":"otPiYFmBFPKr","executionInfo":{"status":"ok","timestamp":1673036461610,"user_tz":-210,"elapsed":12,"user":{"displayName":"Samin Mehdizadehsani","userId":"02586135374726691422"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from transformers import ElectraTokenizer, ElectraForMultipleChoice\n","from transformers import RobertaTokenizer, RobertaForMultipleChoice\n","from transformers import BertTokenizer, BertForMultipleChoice\n","from transformers import XLMRobertaTokenizer, XLMRobertaForMultipleChoice\n","import random\n","\n","models = {\n","          'bert':{'Model':BertForMultipleChoice.from_pretrained(\"bert-base-uncased\"),'Tokenizer':BertTokenizer.from_pretrained(\"bert-base-uncased\")},\n","          'electra':{'Model':ElectraForMultipleChoice.from_pretrained(\"google/electra-base-discriminator\"),'Tokenizer':ElectraTokenizer.from_pretrained(\"google/electra-base-discriminator\")},\n","          'roberta':{'Model':RobertaForMultipleChoice.from_pretrained(\"roberta-base\"),'Tokenizer':RobertaTokenizer.from_pretrained(\"roberta-base\")},\n","          'xlm-roberta': {'Model':XLMRobertaForMultipleChoice.from_pretrained(\"xlm-roberta-base\") ,'Tokenizer':XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")}\n","          }"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j6MHqdbFIOxf","executionInfo":{"status":"ok","timestamp":1673037091967,"user_tz":-210,"elapsed":14685,"user":{"displayName":"Samin Mehdizadehsani","userId":"02586135374726691422"}},"outputId":"d9e3ee3a-2e5b-4935-f67f-e7cf9041ae4d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at google/electra-base-discriminator were not used when initializing ElectraForMultipleChoice: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n","- This IS expected if you are initializing ElectraForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForMultipleChoice were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['sequence_summary.summary.bias', 'classifier.weight', 'sequence_summary.summary.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForMultipleChoice: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMultipleChoice: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing XLMRobertaForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForMultipleChoice were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["results = {'choice0':[],'choice1':[],'prompt':[],'bert':[],'electra':[],'roberta':[],'xlm-roberta':[]}\n","choices = ['Yes. This sentence is true','No. This sentence is false']\n","for i, row in tqdm(df.iterrows(), total=len(df)):\n","  sentence = row['sentence']\n","  prompt = f\"{sentence}.Is this sentence true?\"\n","  choice0 = random.choice(choices)\n","  if(choice0 == 'Yes. This sentence is true'):\n","    choice1 = 'No. This sentence is false'\n","    results['choice0'].append('T') \n","    results['choice1'].append('F')\n","  else:\n","    choice1 = 'Yes. This sentence is true'\n","    results['choice0'].append('F') \n","    results['choice1'].append('T')\n","\n","  labels = torch.tensor(0).unsqueeze(0)\n","  results['prompt'].append(prompt)\n","  for name in models.keys():\n","    model = models[name]['Model']\n","    tokenizer = models[name]['Tokenizer']\n","    model.eval()\n","    model.to(DEVICE)\n","    encoding = tokenizer([prompt, prompt], [choice0, choice1], return_tensors=\"pt\", padding=True)\n","    outputs = model(**{k: v.unsqueeze(0).to(DEVICE) for k, v in encoding.items()}, labels=labels.to(DEVICE))\n","    logits = outputs.logits\n","    ans = torch.argmax(logits).item()\n","    if(ans == 0):\n","      if(choice0 == \"Yes. This sentence true\"):\n","        label = \"T\"\n","      else:\n","        label = \"F\"\n","    else:\n","      if(choice1 == \"Yes. This sentence is true\"):\n","        label = \"T\"\n","      else:\n","        label = \"F\"\n","    results[name].append(label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["df4eb1a6ab1d4063ad8684a960a8dbc0","154498c9ad894e8fa8e640f09c3ae2b7","70b1e8e4820649f8a549c9c3a0427599","282575bafb194d3ab9f7bf4cfc06274e","d7ae865acbf64b7e9036057e3ee5f3ad","f7cdcc61f3c34bb6bbe6c0698e27dd58","5890cd7d95d54128af88d3b68fbc767a","367fab8ae5b14b9cb3643ae07bfac94c","71fc793fca834683853cf83f69ec30c4","49386c77491f42ab98166ac92104e098","f8826dc88563458b8ed90911f13da1ee"]},"id":"DnHo3dNs8Slz","executionInfo":{"status":"ok","timestamp":1673037582450,"user_tz":-210,"elapsed":253847,"user":{"displayName":"Samin Mehdizadehsani","userId":"02586135374726691422"}},"outputId":"2101b32e-3d2c-469d-a840-b85a4f400a68"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2975 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df4eb1a6ab1d4063ad8684a960a8dbc0"}},"metadata":{}}]},{"cell_type":"code","source":["df['prompt'] = results['prompt']\n","df['electra'] = results['electra']\n","df['bert'] = results['bert']\n","df['roberta'] = results['roberta']\n","df['xlm-roberta'] = results['xlm-roberta']\n","df.to_csv('results.csv')"],"metadata":{"id":"-bakCj5ClAke","executionInfo":{"status":"ok","timestamp":1673037586411,"user_tz":-210,"elapsed":519,"user":{"displayName":"Samin Mehdizadehsani","userId":"02586135374726691422"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["models_name = ['electra','bert','roberta','xlm-roberta']\n","for model in models_name:\n","  print(model)\n","  print(classification_report(df['label'], df[model], target_names=[\"F\",\"T\"]))\n"],"metadata":{"id":"FwLVrfUV8n3P","executionInfo":{"status":"ok","timestamp":1673037589280,"user_tz":-210,"elapsed":655,"user":{"displayName":"Samin Mehdizadehsani","userId":"02586135374726691422"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c19c1bd8-5aac-439e-db32-d0a813d4c83a"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["electra\n","              precision    recall  f1-score   support\n","\n","           F       0.75      1.00      0.85      2220\n","           T       0.14      0.00      0.00       755\n","\n","    accuracy                           0.74      2975\n","   macro avg       0.44      0.50      0.43      2975\n","weighted avg       0.59      0.74      0.64      2975\n","\n","bert\n","              precision    recall  f1-score   support\n","\n","           F       0.74      0.57      0.64      2220\n","           T       0.25      0.42      0.31       755\n","\n","    accuracy                           0.53      2975\n","   macro avg       0.50      0.50      0.48      2975\n","weighted avg       0.62      0.53      0.56      2975\n","\n","roberta\n","              precision    recall  f1-score   support\n","\n","           F       0.74      0.63      0.68      2220\n","           T       0.24      0.35      0.29       755\n","\n","    accuracy                           0.56      2975\n","   macro avg       0.49      0.49      0.48      2975\n","weighted avg       0.61      0.56      0.58      2975\n","\n","xlm-roberta\n","              precision    recall  f1-score   support\n","\n","           F       0.74      0.51      0.61      2220\n","           T       0.25      0.47      0.33       755\n","\n","    accuracy                           0.50      2975\n","   macro avg       0.50      0.49      0.47      2975\n","weighted avg       0.62      0.50      0.54      2975\n","\n"]}]}]}